{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-27T16:57:51.396702Z",
     "iopub.status.busy": "2024-11-27T16:57:51.396418Z",
     "iopub.status.idle": "2024-11-27T16:57:52.819979Z",
     "shell.execute_reply": "2024-11-27T16:57:52.819071Z",
     "shell.execute_reply.started": "2024-11-27T16:57:51.396674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"matthewjansen/ucf101-action-recognition\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation + preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T16:58:02.243101Z",
     "iopub.status.busy": "2024-11-27T16:58:02.242764Z",
     "iopub.status.idle": "2024-11-27T16:58:08.016706Z",
     "shell.execute_reply": "2024-11-27T16:58:08.015787Z",
     "shell.execute_reply.started": "2024-11-27T16:58:02.243070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for now doing on one class \n",
    "data_path = '/kaggle/input/ucf101-action-recognition/train/JumpingJack'\n",
    "\n",
    "#extract frames from videos\n",
    "def extract_frames(video_path, frame_size=(64, 64)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Resize frame\n",
    "        frame = cv2.resize(frame, frame_size)\n",
    "        # Convert to grayscale\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "#load all videos and extract frames\n",
    "all_frames = []\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith('.avi'):\n",
    "        video_frames = extract_frames(os.path.join(data_path, file))\n",
    "        all_frames.append(video_frames)\n",
    "\n",
    "#normalize\n",
    "all_frames = [frames / 255.0 for frames in all_frames]\n",
    "\n",
    "#stack all frames from all videos\n",
    "dataset = np.vstack(all_frames)\n",
    "dataset = np.expand_dims(dataset, axis=-1)  # Add channel dimension\n",
    "\n",
    "#for training\n",
    "def create_shifted_frames(data, sequence_length=10):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        x.append(data[i : i + sequence_length])\n",
    "        y.append(data[i + 1 : i + 1 + sequence_length])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x, y = create_shifted_frames(dataset)\n",
    "\n",
    "#split into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Training Dataset Shapes: \", x_train.shape, y_train.shape)\n",
    "print(\"Validation Dataset Shapes: \", x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T16:58:23.397879Z",
     "iopub.status.busy": "2024-11-27T16:58:23.396911Z",
     "iopub.status.idle": "2024-11-27T16:58:36.285036Z",
     "shell.execute_reply": "2024-11-27T16:58:36.284137Z",
     "shell.execute_reply.started": "2024-11-27T16:58:23.397844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "input_layer = layers.Input(shape=(None, 64, 64, 1))     #input layer for sequential data\n",
    "\n",
    "#ConvLSTM layers\n",
    "x = layers.ConvLSTM2D(filters=64, kernel_size=(5, 5), padding=\"same\", return_sequences=True, activation=\"relu\")(input_layer)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ConvLSTM2D(filters=64, kernel_size=(3, 3), padding=\"same\", return_sequences=True, activation=\"relu\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ConvLSTM2D(filters=64, kernel_size=(1, 1), padding=\"same\", return_sequences=True, activation=\"relu\")(x)\n",
    "\n",
    "output_layer = layers.Conv3D(filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "#build the model\n",
    "model = models.Model(input_layer, output_layer)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T16:58:44.217182Z",
     "iopub.status.busy": "2024-11-27T16:58:44.216166Z",
     "iopub.status.idle": "2024-11-27T19:24:05.849912Z",
     "shell.execute_reply": "2024-11-27T19:24:05.848890Z",
     "shell.execute_reply.started": "2024-11-27T16:58:44.217144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "#define callbacks\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    batch_size=8,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T20:03:00.708634Z",
     "iopub.status.busy": "2024-11-27T20:03:00.707852Z",
     "iopub.status.idle": "2024-11-27T20:03:00.774627Z",
     "shell.execute_reply": "2024-11-27T20:03:00.773780Z",
     "shell.execute_reply.started": "2024-11-27T20:03:00.708599Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#aave the trained model\n",
    "model.save('my_trained_model.h5')\n",
    "print(\"Model saved to 'my_trained_model.h5'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T20:03:24.142597Z",
     "iopub.status.busy": "2024-11-27T20:03:24.141952Z",
     "iopub.status.idle": "2024-11-27T20:03:24.280582Z",
     "shell.execute_reply": "2024-11-27T20:03:24.279774Z",
     "shell.execute_reply.started": "2024-11-27T20:03:24.142551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('my_trained_model.h5')\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization\n",
    "\n",
    "Randomly select a sequence from x_val\n",
    "Use the model to predict frames for that input sequence\n",
    "The predicted frames come directly from model.predict(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T20:27:15.019422Z",
     "iopub.status.busy": "2024-11-27T20:27:15.018702Z",
     "iopub.status.idle": "2024-11-27T20:27:17.025653Z",
     "shell.execute_reply": "2024-11-27T20:27:17.024831Z",
     "shell.execute_reply.started": "2024-11-27T20:27:15.019389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_predictions(model, x_val, y_val):\n",
    "    index = np.random.randint(0, len(x_val))\n",
    "    input_seq = x_val[index:index + 1]\n",
    "    true_seq = y_val[index:index + 1]\n",
    "\n",
    "    predicted_seq = model.predict(input_seq)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 10, figsize=(20, 6))\n",
    "    for i in range(10):\n",
    "        axes[0, i].imshow(input_seq[0, i, :, :, 0], cmap='gray')\n",
    "        axes[0, i].set_title(f\"Input {i+1}\")\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        axes[1, i].imshow(true_seq[0, i, :, :, 0], cmap='gray')\n",
    "        axes[1, i].set_title(f\"True {i+1}\")\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "        axes[2, i].imshow(predicted_seq[0, i, :, :, 0], cmap='gray')\n",
    "        axes[2, i].set_title(f\"Predicted {i+1}\")\n",
    "        axes[2, i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T19:54:05.892639Z",
     "iopub.status.busy": "2024-11-27T19:54:05.892247Z",
     "iopub.status.idle": "2024-11-27T19:54:05.897520Z",
     "shell.execute_reply": "2024-11-27T19:54:05.896551Z",
     "shell.execute_reply.started": "2024-11-27T19:54:05.892608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(predicted_frames.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T20:23:27.638654Z",
     "iopub.status.busy": "2024-11-27T20:23:27.638264Z",
     "iopub.status.idle": "2024-11-27T20:23:35.758333Z",
     "shell.execute_reply": "2024-11-27T20:23:35.757218Z",
     "shell.execute_reply.started": "2024-11-27T20:23:27.638621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install opencv-python moviepy numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T20:29:20.225555Z",
     "iopub.status.busy": "2024-11-27T20:29:20.225154Z",
     "iopub.status.idle": "2024-11-27T20:29:21.807228Z",
     "shell.execute_reply": "2024-11-27T20:29:21.806387Z",
     "shell.execute_reply.started": "2024-11-27T20:29:20.225493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_predictions(model, x_val, y_val):\n",
    "    index = np.random.randint(0, len(x_val))\n",
    "    input_seq = x_val[index:index + 1]\n",
    "    true_seq = y_val[index:index + 1]\n",
    "    predicted_seq = model.predict(input_seq)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 10, figsize=(20, 6))\n",
    "    for i in range(10):\n",
    "        axes[0, i].imshow(input_seq[0, i, :, :, 0], cmap='gray')\n",
    "        axes[0, i].set_title(f\"Input {i+1}\")\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].imshow(true_seq[0, i, :, :, 0], cmap='gray')\n",
    "        axes[1, i].set_title(f\"True {i+1}\")\n",
    "        axes[1, i].axis('off')\n",
    "        axes[2, i].imshow(predicted_seq[0, i, :, :, 0], cmap='gray')\n",
    "        axes[2, i].set_title(f\"Predicted {i+1}\")\n",
    "        axes[2, i].axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return input_seq, true_seq, predicted_seq\n",
    "\n",
    "input_frames, true_frames, predicted_frames = visualize_predictions(model, x_val, y_val)\n",
    "\n",
    "frames_to_video_opencv(predicted_frames, 'predicted_video2.avi')\n",
    "combine_input_true_predicted_video(\n",
    "    input_frames=input_frames, \n",
    "    true_frames=true_frames, \n",
    "    predicted_frames=predicted_frames, \n",
    "    output_path='combined_video2.avi'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T20:42:23.836687Z",
     "iopub.status.busy": "2024-11-27T20:42:23.835915Z",
     "iopub.status.idle": "2024-11-27T20:42:32.068896Z",
     "shell.execute_reply": "2024-11-27T20:42:32.067778Z",
     "shell.execute_reply.started": "2024-11-27T20:42:23.836652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install opencv-python moviepy numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T20:44:24.884189Z",
     "iopub.status.busy": "2024-11-27T20:44:24.883828Z",
     "iopub.status.idle": "2024-11-27T20:44:24.894235Z",
     "shell.execute_reply": "2024-11-27T20:44:24.893349Z",
     "shell.execute_reply.started": "2024-11-27T20:44:24.884156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def create_transition_video(model, x_val, y_val, output_path='prediction_video121.avi'):\n",
    "    \"\"\"\n",
    "    Generate a video that shows input frames, a transition screen, and predicted frames.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The trained prediction model\n",
    "    - x_val: Input validation sequences\n",
    "    - y_val: True validation sequences\n",
    "    - output_path: Path to save the output video\n",
    "    \n",
    "    Returns:\n",
    "    - Path to the generated video file\n",
    "    \"\"\"\n",
    "\n",
    "    index = np.random.randint(0, len(x_val))\n",
    "    input_seq = x_val[index:index + 1]\n",
    "    true_seq = y_val[index:index + 1]\n",
    "    \n",
    "    predicted_seq = model.predict(input_seq)\n",
    "    \n",
    "    frames = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        input_frame = input_seq[0, i, :, :, 0]\n",
    "        input_frame = (input_frame * 255).astype(np.uint8)\n",
    "        \n",
    "        input_frame_color = cv2.cvtColor(input_frame, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        frames.append(input_frame_color)\n",
    "    \n",
    "    transition_frame = np.ones((input_seq.shape[2], input_seq.shape[3], 3), dtype=np.uint8) * 255\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(transition_frame, 'PREDICTION STARTS', \n",
    "                (50, transition_frame.shape[0]//2), \n",
    "                font, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    for _ in range(5):\n",
    "        frames.append(transition_frame)\n",
    "    \n",
    "    for i in range(10):\n",
    "        pred_frame = predicted_seq[0, i, :, :, 0]\n",
    "\n",
    "        pred_frame = (pred_frame * 255).astype(np.uint8)\n",
    "        \n",
    "        pred_frame_color = cv2.cvtColor(pred_frame, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        frames.append(pred_frame_color)\n",
    "    \n",
    "    height, width = frames[0].shape[:2]\n",
    "    fps = 10  \n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    \n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Video saved to {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T20:44:28.779533Z",
     "iopub.status.busy": "2024-11-27T20:44:28.779156Z",
     "iopub.status.idle": "2024-11-27T20:44:28.875383Z",
     "shell.execute_reply": "2024-11-27T20:44:28.874592Z",
     "shell.execute_reply.started": "2024-11-27T20:44:28.779483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "video_path = create_transition_video(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without transition frame\n",
    "No white frame between input and predicted frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T20:48:08.189294Z",
     "iopub.status.busy": "2024-11-27T20:48:08.188489Z",
     "iopub.status.idle": "2024-11-27T20:48:08.197216Z",
     "shell.execute_reply": "2024-11-27T20:48:08.196193Z",
     "shell.execute_reply.started": "2024-11-27T20:48:08.189260Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def create_transition_video(model, x_val, y_val, output_path='prediction_video131.avi'):\n",
    "    \"\"\"\n",
    "    Generate a video that shows input frames and predicted frames.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The trained prediction model\n",
    "    - x_val: Input validation sequences\n",
    "    - y_val: True validation sequences\n",
    "    - output_path: Path to save the output video\n",
    "    \n",
    "    Returns:\n",
    "    - Path to the generated video file\n",
    "    \"\"\"\n",
    "    #randomly select a sequence\n",
    "    index = np.random.randint(0, len(x_val))\n",
    "    input_seq = x_val[index:index + 1]\n",
    "    true_seq = y_val[index:index + 1]\n",
    "    \n",
    "    predicted_seq = model.predict(input_seq)\n",
    "    \n",
    "    frames = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        input_frame = input_seq[0, i, :, :, 0]\n",
    "        \n",
    "        input_frame = (input_frame * 255).astype(np.uint8)\n",
    "\n",
    "        input_frame_color = cv2.cvtColor(input_frame, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        frames.append(input_frame_color)\n",
    "    \n",
    "    for i in range(10):\n",
    "        pred_frame = predicted_seq[0, i, :, :, 0]\n",
    "\n",
    "        pred_frame = (pred_frame * 255).astype(np.uint8)\n",
    "        \n",
    "        pred_frame_color = cv2.cvtColor(pred_frame, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        frames.append(pred_frame_color)\n",
    "    \n",
    "    height, width = frames[0].shape[:2]\n",
    "    fps = 10  \n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    \n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Video saved to {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-27T20:48:15.604239Z",
     "iopub.status.busy": "2024-11-27T20:48:15.603895Z",
     "iopub.status.idle": "2024-11-27T20:48:15.706251Z",
     "shell.execute_reply": "2024-11-27T20:48:15.705241Z",
     "shell.execute_reply.started": "2024-11-27T20:48:15.604209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "video_path = create_transition_video(model, x_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2807884,
     "sourceId": 4849320,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
